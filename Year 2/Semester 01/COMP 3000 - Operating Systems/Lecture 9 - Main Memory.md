#### **Main Memory and Multiprogramming**

- **CPU access:** CPU can only directly access **main memory** and **registers**.
- **Memory operations take time**:
    - Register access → 1 CPU cycle (or less)
    - Main memory → several cycles → may **stall the CPU**
    - **Cache** sits in between to reduce latency.

- **Multiprogramming problem:**
    - Multiple programs need to run concurrently.
    - Main memory is limited → loading all programs together is hard.
    - Leads to **fragmentation and protection issues**.


---
#### **Try-1: Load all programs into memory one after another**

- Idea: Allocate memory **contiguously** for each program in a single partition or segment.
    
- **Mechanism:**
    - Each process can only access **its own address space**.
    - **Base and limit registers** define accessible memory:
        - **Base register:** starting physical address of the process
        - **Limit register:** size of the addressable memory
    - **Hardware protection:** CPU checks each memory access against these registers.

- **Problem:**
    - Fixed partitions → wasted space (internal fragmentation)
    - Large programs → cannot fit if memory is fragmented
    - Moving programs requires recompiling (if addresses are absolute)


---
#### **Address Binding**

Binding associates program instructions and data with memory addresses. Can happen at:
1. **Compile-time:**
    - Memory addresses known in advance → absolute code generated
    - Must recompile if program is loaded elsewhere
2. **Load-time:**
    - Memory location not fixed → relocatable code generated
    - Base register added at load-time → program can be loaded anywhere
3. **Execution-time:**
    - Memory location determined at run-time → allows **dynamic relocation**
    - **MMU (Memory Management Unit)** required
    - Logical addresses (used by CPU) → mapped to physical addresses (seen by memory)


---
#### **Memory-Management Unit (MMU)**

- Hardware device that maps **virtual/logical addresses** → **physical addresses**.
- Relocation register (a generalization of base register) added to **logical addresses** at run-time.
- Benefits:
    - Programs don’t know physical memory → easier to move processes
    - Provides protection: process cannot access addresses outside its range


---
#### **Contiguous Memory Allocation**

- Memory is divided into **blocks or partitions**.
    
- Two common approaches:
    1. **Fixed-sized partitions:** Each partition is fixed in size. Programs are assigned to a partition large enough to hold them.
        - **Problem:** Internal fragmentation (unused space inside a partition).
    2. **Variable-sized partitions:** Partitions are made just large enough for each program.
        - **Problem:** External fragmentation (gaps between partitions accumulate over time).

- **Segments:** logical divisions of a program (code, data, stack). Can be allocated contiguously, but same fragmentation issues occur.


---
#### **Try-2:  Paging**

- **Problem with contiguous allocation:** still too rigid and inefficient.
    
- **Paging solution:**
    - Break memory into **frames** (physical) and programs into **pages** (logical)
    - Pages can be loaded into **any free frame** → **eliminates external fragmentation**
    - **Internal fragmentation** limited to last page

- **Cost:** Requires **page tables** → extra memory overhead and address translation

**Operating systems can support _multiple_ page sizes**.
This is called:
- **Multiple page sizes**
- **Variable page sizes**
- **Huge pages**
- **Superpages**
- **Mixed page-size paging**

**Page Table Structure**
Each entry typically contains:
- Frame number (where page is in physical memory)
- Present/absent bit (is page in memory?)
- Protection bits (R/W/X)
- Optional: dirty/modified bit, reference bit

##### Single-level paging
**Single-level paging** is the simplest paging model where each logical address is divided into one page number and one offset, and the page number indexes a single page table to obtain the frame number used to form the physical address.

> CPU generates a logical address → MMU looks it up in the page table → physical address accessed


Address generated by CPU is divided into:  
- The **page number** (p) tells _which virtual page_ we’re accessing.
- The **offset** (d) tells _where inside that page_ we’re accessing.
- For given logical address space 2m and page size 2n

If your page size = **2ⁿ bytes**:
- The offset requires **n bits**
- The page number uses **the remaining bits**

If the virtual address has **m bits** total:
```
m-bit address = (m–n)-bit page number  +  n-bit offset
```

That’s where the magic formula comes from:
Logical Address Space = 2ᵐ
Page Size = 2ⁿ
Number of pages = 2^(m–n)


Example:
Suppose:
- Virtual address size: **16 bits** → logical address space = 2¹⁶ = 64 KB
- Page size: **2⁸ = 256 bytes**

So:
- Offset = **n = 8 bits**
- Page number = **m – n = 16 – 8 = 8 bits**

So the 16-bit logical address is split like this:
```
[ 8-bit page# ] [ 8-bit offset ]
```

If the address is:
```
LA = 0x3A7C  =  00111010 01111100₂
```

Split into:
```
Page number = 00111010₂ = 0x3A = page 58
Offset      = 01111100₂ = 0x7C = byte 124 within that page
```


---
#### **What if all programs don’t fit in main memory?**

- **Swapping:** Move processes in/out of memory as needed → CPU can run processes that are not fully in memory
    
- **Virtual memory:** Generalizes swapping:
    - Only **needed pages** are brought into memory
    - Supports programs **larger than physical memory**
    - Enables demand paging and page replacement algorithms


**Key Concepts From Slides**
- **Logical vs Physical addresses:** CPU sees logical, MMU translates to physical
- **Base/relocation registers:** Provide dynamic relocation and protection
- **Memory binding:** Can occur at compile, load, or execution time
- **Main memory + registers = only directly accessible storage**


**Dynamic Allocation Problem:**
First-fit: Allocate the first hole that is big enough  
Best-fit: Allocate the smallest hole that is big enough; must search entire list, unless ordered by size  
	Produces the smallest leftover hole  
Worst-fit: Allocate the largest hole; must also search entire list  
	Produces the largest leftover hole  
Comparing these:  
	First-fit and best-fit better than worst-fit in terms of speed and storage utilization



---
#### Compaction

With fixed partitions / variable partitions and **contiguous allocation**, when processes come and go, you get **holes** (free blocks) scattered in memory → **external fragmentation**.

**Compaction** = moving processes in memory to **eliminate holes** and create **one large contiguous free block**.
- You _copy_ processes to new addresses.
- The “amount of memory relocation” = **total number of words moved** (sum of sizes of processes that get copied).

Most textbooks assume a simple compaction algorithm:
> Scan memory from low addresses upward and slide each process down to the lowest possible free address, preserving order.  Only move enough memory to create a large enough block of contiguous memory to accept the new request.


#### Internal Fragmentation
**Definition:**
Internal fragmentation happens when a process is allocated a **fixed-size block** of memory, but it **does not use all of it**.  
The _unused_ part **inside** the allocated block is wasted.

> **Wasted space _inside_ an allocated region.**

Example:
Suppose the OS allocates memory in blocks of **100 words**.
- Process A needs **73 words**, so it gets a 100-word block
- Unused part = **100 − 73 = 27 words**

→ This 27 words is **internal fragmentation**  
(because it is _inside_ the allocated block, and cannot be used by others)


#### External Fragmentation
**Definition:**
External fragmentation happens when **free memory exists**, but it is **broken up into many small holes** so that **no single hole is large enough** for the next allocation.

> **Total free memory is enough**, but it’s not **contiguous**, so you can’t allocate it.

Example (classic):
Free memory holes:
- 500 bytes
- 300 bytes
- 200 bytes
- 100 bytes

Total free = **1100 bytes**

A new process needs **700 bytes**.  
Do we have 700 bytes free?
- Total = 1100, _yes_
- But the biggest single hole = 500
→ Allocation fails even though total free space is enough.


#### Variable partitioning
This means **contiguous variable-size allocation** — the OS allocates _exactly the amount requested_ (or very close to it).

#### Fixed partitioning
- Memory is divided into fixed-size partitions.
- A process must fit into one partition.
- If a partition is 1000 words and a process uses 700 → **300 wasted inside**.


#### Address Binding
When a program is mapped to memory, the OS must decide **when** to translate its logical addresses to physical addresses.

There are 3 times this can happen:
	**1. Compile-time binding**
	Physical addresses are decided **at compile time**  
	→ The program is built with _absolute_ physical addresses.
	**2. Load-time binding**
	Physical addresses are decided **when the program is loaded** into memory.  
	→ The loader chooses the base address.
	**3. Execution-time binding**
	Physical addresses are determined **dynamically during execution**  
	(using page tables, MMU, segmentation, etc.)

---
#### Step By Step Loading A Program

1. **A program starts (process creation)**
When you run a program:
- The OS loads **just a tiny part** of it into RAM:
    - the first page or two (enough to start executing)
    - some PCB data, stack, minimal runtime area
- The rest of the program **stays on disk**.

This is called **lazy loading** or **demand paging**.


2. **Virtual Memory is divided into pages**
The program’s address space (virtual memory) is divided by the OS and compiler:
```
Page 0
Page 1
Page 2
...
Page N
```
Each page is usually 4 KB (common) or sometimes 8 KB, 16 KB, etc.
These pages represent the **virtual** layout of the process.


3. **RAM is divided into frames**
Physical memory (RAM) is divided into **frames** of the same size as pages:
```
Frame 0
Frame 1
Frame 2
...
Frame M
```


4. **MMU uses a page table to translate Virtual → Physical**
The MMU (Memory Management Unit) reads the page table:
```
Virtual Page X → Physical Frame Y
```
But **not all pages are mapped** — only pages that are currently in RAM.


5. **CPU tries to access a page → MMU checks if it’s in RAM**
Case 1: **Page is in RAM**  
	→ MMU translates address → CPU executes normally.

Case 2: **Page is NOT in RAM**  
	→ Page Fault occurs  
	→ OS brings the page in from disk (swap, executable file, etc).

This is **demand paging**.


**Whole Process:**
	**Start process**
	↓  
	OS loads **a minimal set** of pages  
	↓  
	MMU maps virtual pages → physical frames  
	↓  
	CPU executes  
	↓  
	If a page is needed but not loaded → **page fault → bring from disk**  
	↓  
	If RAM is full → OS uses a replacement algorithm (LRU, CLOCK, etc.) to evict pages  
	↓  
	Process continues

**Only what's needed is loaded into RAM**

Virtual memory is the per-process, logical address space of a program.  
It is divided into fixed-size pages (4 KB).  
These pages are assigned virtual page numbers starting at 0.  
The OS/MMU maps these virtual pages to physical frames in RAM using the page table.  
Only the pages the CPU actually touches are loaded into RAM (demand paging).  
The rest remain on disk until needed.